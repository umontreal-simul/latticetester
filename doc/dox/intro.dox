/**
 * \page a_intro Background
 *
 *
 * *LatticeTester* is a software library and tool to measure theoretical measures
 * of uniformity (or figures of merit) for lattices in the \f$t\f$-dimensional the real space \f$\mathbb{R}^t\f$
 * that contain \f$\mathbb{Z}^t\f$ as a sublattice or are contained in \f$\mathbb{Z}^t\f$.
 * Such lattices are encountered for example in quasi-Monte Carlo integration
 * (by lattice rules) and in the analysis of uniform random number generators
 * defined by linear recurrences modulo a large integer.
 * Measures of uniformity include the length of the shortest nonzero vector
 * in the lattice or in its dual (the spectral test), the Beyer ratio,
 * \f$\mathcal{P}_\alpha\f$, as well as figures of merit that take normalized versions
 * of these measures over projections of the lattice on subsets of the \f$t\f$ coordinates,
 * and then take a weighted sum or the worst-case over the class of considered projections.
 * *LatticeTester* is used in particular in the *Lattice Builder* and *LatMRG*
 * software tools, designed to construct and analyze lattice rules and linear generators.
 *
 * The purpose of *LatticeTester* is to compute various figures of merit that
 * serve as measures of uniformity for lattices in the \f$t\f$-dimensional real
 * space \f$\mathbb{R}^t\f$ that contain \f$\mathbb{Z}^t\f$ as a sublattice or are contained in \f$\mathbb{Z}^t\f$
 * \cite vLEC00b \cite mSLO94a .
 *
 * The lattices we consider are discrete vector spaces in \f$\mathbb{R}^t\f$ and
 * one is often interested in the (finite) intersection of the lattice
 * with the \f$t\f$-dimensional unit hypercube \f$[0,1)^t\f$.
 * This is the case for *Lattice rules*, which are multivariate integration
 * methods that take the average value of a function at this set
 * of points (sometimes randomly shifted modulo 1)
 * to estimate the integral of the function over the unit cube
 * \cite vLEC00b \cite vLEC09f \cite mSLO94a.
 * Bounds on the (mean square) integration error can be obtained in
 * terms of figures of merit computed by the present software.
 *
 * This same set of points is also the set of all vectors of \f$t\f$ successive
 * values produced by certain types of linear congruential generators
 * in scalar or matrix form.  In that context, we want the point set
 * to cover the unit hypercube as uniformly as possible, and a standard
 * way of measuring this uniformity is the spectral test
 * \cite rCOV67a \cite rKNU98a \cite rLEC97c, that computes the length of the
 * shortest nonzero vector in the dual lattice.
 * The inverse of this length represents the maximal distance between successive hyperplanes
 * in a family of equidistant hyperplanes that contain all the lattice points.
 * We want this maximal distance to be not too large for the points to cover the space evenly.
 * *LatticeTester* permits one to compute this distance for the lattice and for any of its
 * projections over a subset of coordinates.
 *
 * In these applications, the lattice of interest contains \f$\mathbb{Z}^t\f$ and its dual lattice
 * is contained in \f$\mathbb{Z}_t\f$.
 * An important difference between these two applications (from the practical viewpoint)
 * is that the number of lattice points per unit of volume,
 * i.e., the number \f$n\f$ of lattice points in the unit hypercube \f$[0,1)^t\f$,
 * is usually modest (at most in the thousands or millions) for lattice rules,
 * and much larger (say, from \f$2^{100}\f$ to \f$2^{1000}\f$ or more)  in the case of
 * random number generators (because the period of the generator typically 
 * cannot exceed \f$n\f$). For this reason, the figures of merit for these two 
 * applications are typically not the same.
 * The most relevant measures for lattice rules (e.g., \f$\mathcal{P}_\alpha\f$ with weights)
 * require a computing time that increases at least linearly (or faster)
 * with \f$n\f$ and are unusable when \f$n \ge 2^{100}\f$.
 * The spectral test, whose computing time is exponential in \f$t\f$ but only
 * logarithmic in \f$n\f$, appears more appropriate in this situation.
 *
 * For more details on lattices, see for example \cite mCON99a \cite mSLO94a.
 * Here we use \f$t\f$ for the lattice dimension, as do many papers and books on
 * linear congruential generators (e.g., \cite rKNU98a \cite rLEC90a \cite rLEC96b).
 * Most papers on lattice rules use \f$s\f$ or \f$d\f$ instead.
 *
 * The rest of this document is organized as follows.
 * In the next section, we define the lattices considered here and recall their main
 * properties.
 * In section \ref sec_merit, we define and discuss the various figures of merit
 * that the software can compute.
 *
 * \section lattices Lattices in the Real Space
 *
 * \subsection lattices_def Definition of a Lattice
 *
 * We start with *lattices* over \f$\mathbb{Z}\f$ (or \f$\mathbb{Z}\f$-lattices)
 * in the real space \f$\mathbb{R}^t\f$, which are discrete subspaces of the 
 * real vector space \f$\mathbb{R}^t\f$ that can be expressed as
 * \f[
 *  L_t = \left\{\mathbf{v} = \sum_{j=1}^t z_j\mathbf{v}_j\mid \mbox{ each } z_j\in\mathbb{Z}\right\}
 *      = \oplus_{j=1}^t \mathbb{Z} \mathbf{v}_j,
 * \label {eq:lattice}
 * \f]
 * where \f$t\f$ is a positive integer, and
 * \f$\mathbf{v}_1,\dots,\mathbf{v}_t\f$ are linearly independent vectors in \f$\mathbb{R}^t\f$
 * which form a **basis** of the lattice.
 * The matrix \f$\mathbf{V}\f$, whose \f$i\f$th row is \f$\mathbf{v}_i\f$, is the
 * corresponding **generator matrix** of \f$L_t\f$.
 * A comprehensive treatment of such lattices can be found in \cite mCON99a .
 *
 * The determinant of the matrix \f$\mathbf{V}\f$ is equal to the volume of the
 * fundamental parallelepiped
 * \f$\{\mathbf{v} = \lambda_1\mathbf{v}_1 + \cdots + \lambda_t\mathbf{v}_t \mid
 * 0\le \lambda_i\le 1\f$ for \f$1\le i\le t\}\f$.  It is independent of
 * the choice of basis. It is called the **determinant** of \f$L_t\f$.
 * The quantity \f$n = 1/\det(L_t) = 1/\det(\mathbf{v}) = \det(\mathbf{v}^{-1})\f$
 * is called the **density** of \f$L_t\f$ and it represents the
 * average number of points per unit of volume.
 * When \f$L_t\f$ contains \f$\mathbb{Z}^t\f$, the density \f$n\f$ is an integer equal to the
 * cardinality of the point set \f$L_t \cap [0,1)^t\f$.
 *
 * For a given lattice \f$L_t\f$ and a subset of coordinates
 * \f$I = \{i_1,\dots,i_d\} \subseteq \{1,\dots,t\}\f$, denote by \f$L_t(I)\f$
 * the projection of \f$L_t\f$ over the \f$d\f$-dimensional subspace determined
 * by the coordinates in \f$I\f$.
 * This projection is also a lattice, whose density divides that of \f$L_t\f$.
 * There are exactly \f$\det(L_t(I))/\det(L_t)\f$ points of \f$L_t\f$ that are
 * projected onto each point of \f$L_t(I)\f$.
 * In group theory language, \f$L_t(I)\f$ corresponds to a coset of \f$L_t\f$.
 *
 * A **shifted lattice** is a lattice \f$L_t\f$ shifted by a constant vector
 * \f$\mathbf{v}_0\not\in L_t\f$, i.e., a point set of the form 
 * \f$L'_t = \{\mathbf{v}+\mathbf{v}_0 : \mathbf{v} \in L_t\}\f$, where 
 * \f$L_t\f$ is a lattice.  The uniformity of a shifted lattices \f$L'_t\f$ can
 * be analyzed by subtracting the shift and analyzing the (unshifted) lattice 
 * \f$L_t\f$.
 *
 * For a positive integer \f$m\f$,
 * The **dual lattice** of \f$L_t\f$ is defined as
 * \f[
 * L_t^* = \{\mathbf{h} \in \mathbb{R}^t \mid \forall \mathbf{v} \in L_t, \mathbf{h}\cdot\mathbf{v} \in \mathbb{Z} \}.
 * \f]
 * The **dual** of a given basis \f$\mathbf{v}_1,\dots,\mathbf{v}_t\f$ is the set of
 * vectors \f$\mathbf{w}_1,\dots,\mathbf{w}_t\f$ in \f$\mathbb{R}^t\f$
 * such that \f$\mathbf{v}_i\cdot\mathbf{w}_j = \delta_{ij}\f$, where \f$\delta_{ij}=1\f$
 * if \f$i=j\f$, and \f$\delta_{ij}=0\f$ otherwise.
 * It forms a basis of the dual lattice.
 * These \f$\mathbf{w}_j\f$'s are the columns of the matrix \f$\mathbf{v}^{-1}\f$,
 * the inverse of the matrix \f$\mathbf{v}\f$.
 *
 * \subsection lattices_rescaling Rescaling to lattices in the integer space
 *
 * For the applications targeted by this software, the lattice \f$L_t\f$ either contains,
 * or is contained in, the integer lattice \f$\mathbb{Z}^t\f$; i.e., 
 * \f$\mathbb{Z}^t\subseteq L_t\f$ or \f$L_t\subseteq \mathbb{Z}^t\f$. When 
 * \f$L_t\f$ satisfies the first condition, then its dual satisfies the second,
 * and vice-versa. When \f$\mathbb{Z}^t\subseteq L_t\f$, there is always an 
 * integer \f$m \ge 1\f$ such that all the coordinates of all vectors are 
 * multiple of \f$1/m\f$, and one can rescale \f$L_t\f$ by a factor of \f$m\f$
 * to obtain the \f$\mathbf{m}\f$ **-scaled** lattice \f$\Lambda_t = m L_t\f$
 * whose vectors have only integer coordinates, i.e., \f$\Lambda_t \subseteq
 * \mathbb{Z}^t\f$ is a \f$\mathbb{Z}\f$-lattice in \f$\mathbb{Z}^t\f$.
 * The rows of \f$m \mathbf{V}\f$ form a basis of \f$\Lambda_t\f$, also called an \f$\mathbf{m}\f$ **-scaled basis** for \f$L_t\f$,
 * and the columns of \f$\mathbf{W}\f$ are its \f$\mathbf{m}\f$ **-dual basis**.
 * They are a basis of \f$\Lambda^*_t = L^*_t\f$, the \f$\mathbf{m}\f$ **-dual lattice** of \f$\Lambda_t\f$.
 * When \f$L_t\subset \mathbb{Z}^t\f$, there is an integer \f$m \ge 1\f$ such that
 * \f$m L^*_t \subseteq \mathbb{Z}^t\f$, in which case we can define \f$\Lambda^*_t = m L^*_t\f$
 * and \f$\Lambda_t = L_t\f$.
 *
 * More generally, if there are positive integers \f$m_1\f$ and \f$m_2\f$ such that
 * \f$\Lambda_t = m_1 L_t \subseteq \mathbb{Z}^t\f$ and \f$\Lambda_t^* = m_2 L_t^* \subseteq \mathbb{Z}^t\f$,
 * then we can work with \f$\Lambda_t\f$ and its \f$m\f$-dual lattice \f$\Lambda_t^*\f$,
 * where \f$m = m_1 m_2\f$.  That is, we rescale both the lattice and its dual.
 * Note that scaling a lattice by \f$m\f$ multiplies all vector lengths by \f$m\f$ and all volumes by \f$m^t\f$,
 * and it divides the lattice density by \f$m^t\f$.
 *
 * \remark
 *      **Pierre**: Oups, ici je vois que la densite devient un nombre reel tres petit...
 *      Pas 100% certain que c'est une bonne idee de travailler avec \f$\Lambda_t\f$ et oublier
 *      le scaling, car cela change la normalisation... Mais cela rend quand meme les choses plus generales.
 *
 * In this software and in the remainder of this document, we assume that the appropriate
 * rescaling has already been done and we always work directly with the rescaled versions
 * \f$\Lambda_t\f$ and \f$\Lambda_t^*\f$, which are \f$\mathbb{Z}\f$-lattices over \f$\mathbb{Z}^t\f$
 * and are \f$m\f$-dual to each other.
 * The advantage is that in this framework, all vector coordinates are integers
 * and this permit us to always and easily represent them exactly on the computer.
 * With a slight abuse of notation, we will use \f$\mathbf{V}\f$ with columns \f$\mathbf{V}_1,\dots,\mathbf{V}_t\f$
 * to represent a basis of \f$\Lambda_t\f$ and \f$\mathbf{W}\f$ with rows \f$\mathbf{W}_1,\dots,\mathbf{W}_t\f$
 * for a basis of \f$\Lambda_t^*\f$.
 *
 * A \f$\mathbb{Z}\f$-lattice \f$\Lambda_t\f$ can be uniquely specified by selecting a basis \f$\mathbf{V}\f$
 * of \f$t\f$ linearly independent vectors in \f$\mathbb{Z}^t\f$.
 * The \f$m\f$-dual basis \f$\mathbf{W}\f$ can then be computed for any integer \f$m\ge 2\f$.
 * However, the entries of \f$\mathbf{W}\f$ are not necessarily all integers for any \f$m\f$;
 * this holds only under certain conditions on \f$\mathbf{V}\f$ and \f$m\f$.
 * In the applications targeted by this software, the basis and its \f$m\f$ dual are
 * typically constructed together in a way that these conditions are guaranteed to
 * be satisfied.  Our software can take advantage of this.
 *
 * \remark **Pierre**: Must define *rescaled integration lattice of rank 1* earlier.
 *
 * In the case of a rescaled integration lattice of rank 1, it suffices to specify the generating vector
 * \f$\mathbf{a} = \mathbf{V}_1\f$ and an integer \f$m > 0\f$ such that the vectors \f$\mathbf{V}_2= m \mathbf{e}_2, \dots, \mathbf{V}_t = m \mathbf{e}_t\f$
 * complete a basis, where the \f$\mathbf{e}_j\f$ are the unit vectors.
 *
 * For all lattices, we want to be able to easily enumerate the lattice points
 * that lie in the scaled unit hypercube \f$[0,m)^t\f$ for an appropriate scaling factor \f$m\f$;
 * i.e., the points of \f$\Lambda_t \cap [0,m)^t\f$, and perhaps their rescaled versions to \f$[0,1)^t\f$.
 * For a rescaled integration lattice of rank 1, this is easy: These are the points of the form
 * \f$\mathbf{V} = i \mathbf{V}_1 \bmod 1\f$ for \f$i=0,1,2, \dots\f$.
 * 
 * \remark **Pierre**:It would be good to have a way to enumerate the points of
 *  \f$L_t \cap [0,1)^t\f$ for a more general lattice.
 *
 * \section sec_merit Measures of Uniformity
 *
 * \remark **Pierre**: See Section 3.2.8 of my class notes for more details on the uniformity measures,
 * how to compute them, and how to normalize them to values between 0 and 1.
 *
 * \subsection spectral Shortest Nonzero Lattice Vector
 *
 * The Euclidean length \f$\mathit{l}\f$ of the shortest nonzero lattice vector
 * in the lattice \f$\Lambda_t\f$, say with Euclidean norm,
 * corresponds to the distance between the nearest lattice points.
 * All integer multiples of this shortest vector are regularly-spaced points at distance \f$\mathit{l}\f$
 * of each other on a straight line
 * that passes through the origin, and the entire lattice is covered by shifted replicates
 * of this straight line.  A shorter distance between successive points on the line means
 * more points per unit of length on the line, which means that all lattice points are covered
 * by fewer lines per unit of volume, that are farther away from each other.  This is undesirable.
 *
 * \todo **Pierre**: Add an example of this, with a figure.
 *
 * That is, for a given lattice density \f$\eta\f$, for good uniformity,
 * we want the shortest nonzero vector to be long.
 * This motivates taking this \f$\mathit{l}\f$ as a measure of uniformity,
 * which we want to maximize.
 *
 * \remark **Pierre**: Attention: Dans \f$\Lambda_t\f$, avec un scaling par le 
 * facteur \f$m\f$, la densit\'e a \'et\'e r\'eduite par le facteur \f$m^t\f$.
 * Elle d\'epend maintenant de \f$t\f$ et est souvent tr\`es proche de 0.
 *
 * We can view the lattice as a way of packing the space by non-overlapping spheres of
 * radius \f$\mathit{l}/2\f$, with one sphere centered at each lattice point.
 * We have \f$\eta\f$ spheres per unit of volume.
 * If we rescale by the factor \f$2/\mathit{l}\f$ so that the radius of each sphere is 1,
 * we obtain \f$\delta_t = (\mathit{l}/2)^t \eta\f$ unit spheres per unit volume.
 * This number \f$\delta_t\f$ is called the {\em center density\/} of the lattice.
 * For a general \f$t\f$-dimensional lattice, it has the upper bound
 * \f$\delta_t^* = (\gamma_t /4)^{t/2}\f$, where \f$\gamma_t\f$
 * is the *Hermite constant* for dimension \f$t\f$ \cite mCON99a \cite mGRU87a.
 * This gives the following upper bound \f$\mathit{l}^*(\eta)\f$ on \f$\mathit{l}\f$
 * for a lattice of density \f$\eta\f$:
 * \f[
 *   \mathit{l} \le  \mathit{l}^*(\eta) \stackrel{def}{=} 2(\delta_t^*/\eta)^{1/t} = \gamma_t^{1/2} \eta^{-1/t}.
 * \f]
 * Note that some authors use \f$\gamma_t\f$ to denote our \f$\gamma_t^{1/2}\f$.
 * The Hermite constants \f$\gamma_t\f$ are known exactly only for \f$t\le 8\f$.
 * In those dimensions, the densest lattice packings are
 * attained by the *laminated* lattices \cite mCON99a .
 *
 * Knowing the Hermite constants, or good bounds or approximations of them for \f$t > 8\f$,
 * is useful because it allows us to normalize \f$\mathit{l}\f$ to a value between 0 and 1 by
 * taking \f$\mathit{l}/\mathit{l}^*(\eta)\f$.
 * This is convenient for comparing uniformity measures  for
 * different values of \f$t\f$ and \f$\eta\f$, and we will use that to define figures of merit
 * that take several projections into account.
 * Good values of this measure are close to 1 and bad values are close to 0.
 *
 * Conway and Sloane \cite mCON99a [Table 1.2] give the
 * values of \f$\delta_t^*\f$ for \f$t\le 8\f$, and provide lower and upper
 * bounds on \f$\delta_t^*\f$ for other values of \f$t\f$.
 * The largest value of \f$\mathit{l}^2/n^{2/t}\f$ obtained so far for concrete lattice
 * constructions is a lower bound on \f$\gamma_t\f$, which we denote by
 * \f$\gamma_t^{\mathrm{B}}\f$.  Such values are given in Table 1.2 of \cite mCON99a,
 * page 15, in terms of \f$\delta^*\f$.
 * The laminated lattices, which give the lower bound
 * \f$\mathit{l}^2/n^{2/t} \ge \gamma_t^{\rm L} = 4 \lambda_t^{-1/t}\f$,
 * where the constants \f$\lambda_t\f$ are given in
 * \cite mCON99a [Table 6.1, page 158] for \f$t\le 48\f$,
 * **Pierre**: Check page.
 * are the best constructions in dimensions 1 to 29, except for
 * dimensions 10 to 13.
 * For \f$t\le 8\f$, one has \f$\gamma_t^{\rm L} = \gamma_t\f$.
 *
 * Minkowski proved that there exists lattices with density satisfying
 * \f$\delta_t \ge \zeta(t) / (2^{t-1} V_t)\f$ where
 *  \f$\zeta(t) = \sum_{k=1}^\infty k^{-t}\f$
 * is the Riemann zeta function and \f$V_t = \pi^{t/2} / (t/2)!\f$
 * is the volume of a \f$t\f$-dimensional sphere of radius 1.
 * This bound provides a lower bound \f$\gamma_t^{\rm Z}\f$ on \f$\gamma_t\f$.
 *
 * An upper bound on \f$\gamma_t\f$ is obtained via the bound of Rogers on the
 * density of sphere packings \cite mCON99a .
 * This upper bound can be written as
 * \f$
 *  \gamma_t^{\rm R} = 4* 2^{2R(t)/t}
 * \f$
 * where \f$R(t)\f$ can be found in Table~1.2 of \cite mCON99a  for \f$t\le 24\f$,
 * and can be approximated with \f$O(1/t)\f$ error and approximately 4 decimal
 * digits of precision, for \f$t\ge 25\f$, by
 * \f[
 *  R(t) =   \frac{t}{2} \,\log_2\left(\frac{t}{4\pi e}\right)
 *         + \frac{3}{2} \log_2 (t)
 *         - \log_2 \left(\frac{e}{\sqrt{\pi}}\right)  + \frac{5.25}{t + 2.5}.
 * \f]
 * Table~1 in \cite rLEC99c gives the ratio
 * \f$(\gamma_t^{\rm L} / \gamma_t^{\rm R})^{1/2}\f$,
 * of the lower bound over the upper bound on \f$\mathit{l}\f$, for \f$1\le t\le 48\f$.
 * This ratio tends to decrease with \f$t\f$, but not monotonously.
 *
 * -- Notation for standardized measure.
 *
 * \section bb Computing a shortest vector for the Euclidean norm
 *
 * \subsection bb_IP Integer optimization problem and branch-and-bound procedure
 *
 * We now address the problem of computing a shortest nonzero vector with length \f$\ell_t\f$
 * in the lattice \f$\Lambda_t\f$.  This problem amounts to finding integers \f$z_1,\dots,z_t\f$,
 * not all zero, such that the vector \f$\mathbf{v} = z_1 \mathbf{v}_1 + \cdots + z_t \mathbf{v}_t\f$
 * is as short as possible.  Trying all combinations for those \f$z_j\f$'s is definitely
 * not an efficient option.
 * For the Euclidean norm, we formulate this problem as a quadratic integer programming
 * (optimization) problem with decision variables \f$z_1,\dots, z_t\f$,
 * and show how to solve it by a branch-and-bound (BB) procedure,
 * following the ideas of \cite rDIE75a \cite mFIN85a.
 *
 * Our quadratic integer program (for the Euclidean norm) can be written as
 *   \f{align}{
 *      \text{Minimize }
 *      &
 *      &
 *      \Vert \mathbf{v}\Vert^2
 *      &
 *       =
 *       \mathbf{v}^\mathbf{t} \mathbf{v} & & \\\\
 *     \text{Subject to }
 *      &
 *      &
 *       \mathbf{v}
 *      &
 *       =
 *        \sum_{i=1}^t z_i \mathbf{v}_i,
 *        z_i \in \mathbb{Z}, & & \sum_{i=1}^t |z_i| > 0.\\
 *   \f}
 *
 * Suppose that the basis vectors \f$\mathbf{v}_1,\dots,\mathbf{v}_t\f$ are ordered by increasing length
 * and that our best solution so far is the vector \f$\mathbf{v}_1\f$, with square length
 * \f$\ell^2 = \mathbf{v}'_1 \mathbf{v}_1\f$.
 * This \f$\ell\f$ is an upper bound on the length \f$\ell_t\f$ of a shortest vector.
 *
 * In the BB algorithm, we fix successively \f$z_t\f$,
 * then \f$z_{t-1}\f$, then \f$z_{t-2}\f$, etc.
 * At each step, for any fixed values of \f$z_t,\dots,z_{j-1}\f$ that we consider,
 * we will compute a finite range (interval)
 * of values of \f$z_j\f$ such that all values outside that range cannot lead to a better
 * solution, and will scan the values of \f$z_j\f$ in this range.
 * This interval is obtained as follows.
 *
 * Let us see now how the lower bound \f$s_{j-1}\f$ on \f$V'V\f$ is obtained.
 *
 * At the beginning of the BB procedure,
 * as in \cite rAFF85a \cite mFIN85a \cite rGRO88a \cite mPOH81a,
 * we compute a Cholesky decomposition \cite mGOL89a
 * of the matrix of scalar products of basis vectors:
 * \f[
 *   \mathbf{V}^\mathbf{t} \mathbf{V} = \mathbf{U}^\mathbf{t} \mathbf{U}
 * \f]
 * where \f$\mathbf{U}\f$ is an upper triangular matrix:
 *
 * \f[
 * \mathbf{U} =
 * \begin{pmatrix}
 *      u_{11}   & \ldots & u_{1t} \\\
 *
 *      \vdots & \ddots &\vdots  \\\
 *
 *      \mathbf{0}  & \ldots & u_{tt}
 * \end{pmatrix}
 * \f]
 *
 * Now, if \f$\mathbf{z} = (z_1,\dots,z_t)^\mathbf{t}\f$, \f$\mathbf{v} = \mathbf{V}\mathbf{z}\f$,
 * \f$r_j = \sum_{\ell=j+1}^t u_{j\ell} z_\ell\f$,
 * and \f$s_j = \sum_{k=j+1}^t \left(\sum_{\ell=k}^t u_{k\ell} z_l\right)^2\f$,
 * then we have \cite mPOH81a \cite mFIN85a \cite rAFF85a :
 *
 * \f{eqnarray*}{
 *  \mathbf{v}^\mathbf{t}\mathbf{v} &=& z'\mathbf{V}^\mathbf{t} \mathbf{V} z = z'\mathbf{U}^\mathbf{t} \mathbf{U} z =
 *    \sum_{k=1}^t \left(\sum_{\ell=k}^t u_{k\ell} z_l\right)^2 \\\\
 *   &\ge& \left( u_{jj} z_j + \sum_{\ell=j+1}^t u_{j\ell} z_\ell\right)^2
 *    + \sum_{k=j+1}^t \left(\sum_{\ell=k}^t u_{k\ell} z_l\right)^2 \\\\
 *   &=& (u_{jj} z_j + r_j)^2 + s_{j} \quad = \; s_{j-1}.
 * \f}
 *
 * A better solution must satisfy \f$\mathbf{v}^\mathbf{t}\mathbf{v} < \mathbf{v}_1^\mathbf{t} \mathbf{v}_1\f$, which implies
 *
 * \f$(u_{jj} z_j + r_j)^2 + s_j < \mathbf{v}_1^\mathbf{t} \mathbf{v}_1\f$, i.e.
 *
 *\anchor REF__eq_bounds
 * \f[
 *   \left\lceil {-(\mathbf{v}_1^\mathbf{t} \mathbf{v}_1-s_j)^{1/2} - r_j\over u_{jj}}\right\rceil
 *     \;\le z_j\le\;
 *   \left\lfloor {(\mathbf{v}_1^\mathbf{t} \mathbf{v}_1-s_j)^{1/2} - r_j\over u_{jj}}\right\rfloor.
 *   \tag{bounds}
 * \f]
 *
 * What we have just done is to fix \f$z_t,\dots,z_j\f$ and relax the integrity
 * constraints on \f$z_{j-1},\dots,z_1\f$.
 * When considering the possible values of \f$z_j\f$, we can restrict ourselves
 * to the integers that lie in the interval specified by {@link REF__eq_bounds (bounds)}.
 * Note that \f$s_t = r_t = 0\f$, so at the beginning the bounds on \f$z_t\f$ are
 * given by \f$z_t^2 \le \mathbf{v}_1^\mathbf{t} \mathbf{v}_1\f$.
 *
 *
 * The algorithm thus explores a BB tree in which each node corresponds to
 * a partial solution \f$(z_t,\dots,z_{j-1})\f$.  This node has a son
 * \f$(z_t,\dots,z_{j-1},z_j)\f$ for each value of \f$z_j\f$ that satisfies the bounds
 * {@link REF__eq_bounds (bounds)}.
 * The root has a son for each \f$z_t\f$ such that \f$z_t^2 \le \mathbf{v}_1^\mathbf{t} \mathbf{v}_1\f$.
 * When no \f$z_j\f$ satisfies the bounds {@link REF__eq_bounds (bounds)}, i.e., the interval is empty,
 * the corresponding node has no son, so this branch is a dead end.
 * When we reach a tree leaf that represents a full admissible solution \f$(z_t,\dots,z_1)\f$,
 * we have just found a shorter vector \f$\mathbf{v}\f$ than our current shortest vector \f$\mathbf{v}_1\f$.
 * We can then update the basis in a way that it contains \f$\mathbf{v}\f$ as its new \f$\mathbf{v}_1\f$,
 * and change the other vectors in a way that they still form a basis of our lattice.
 *
 * \remark **Pierre**: Explain ow this can be done.  Idea: The new basis vector \f$\mathbf{v}\f$ is a linear combination
 * of some old basis vectors \f$\mathbf{v}_j\f$ and it will replace one of those vectors.
 * Perhaps these old vectors need to be changed as well.
 *
 * \remark **Pierre**: Give the complete algorithm around here.
 *
 *
 * Here is a pseudo-code for the Branch and Bound algorithm :
 *
 *
 * <center><div class="LatSoft-fbox">\image html branchandbound.png "Pseudo-code for the Branch-and-bound algorithm implemented in LatticeTester." width=700px
 * </div></center>
 *
 *
 * \latexonly
 * \vspace{20pt}
 * \begin{algorithm}
 *     \vspace{10pt}
 *     \caption{Recursive Branch And Bound}
 *        \begin{algorithmic}[1]
 *             \Function{BBrec}{$v, b, h, z$}\Comment{Where  $b = (b_{1},
 *          ..., b_{n})$ ordered basis of a Lattice}
 *             \State $min \gets \Delta^{-}(v, z, h, b)$
 *             \State $max \gets \Delta^{+}(v, z, h, b)$
 *             \If{$max < min$} \Comment{If there is no value possible
 *          for $z_{h}$, it means that this branch cannot lead to a
 *          shorter vector}
 *                 \State return $False$
 *         \ElsIf{h=0}
 *             \State $v \gets \sum_{i=1}^{n}z_{i}b_{i}$
 *             \State return $True$
 *             \EndIf
 *         \For{$i \in [min .. max]$} \Comment{i takes successively the
 *         value $ctr = \frac{min + max}{2}$, $ctr+1$, $ctr-1$, $ctr+2$,
 *         $ctr-2$, etc.}
 *             \If{$i = 0$, $h=1$ and $\forall k \in [2..n], z_{k} = 0$}
 *                 \State \textit{continue} \Comment{Avoid null vector}
 *             \ElsIf{$h=n$ and $i<0$}
 *                 \State \textit{continue}  \Comment{Without losing any
 *                 generality, we consider only the case $z_{n} \geq 0$}
 *             \EndIf
 *             \State $z_{h} = i$
 *                 \If{BBrec(v, b, h-1, z)}
 *                 \State return $True$
 *             \EndIf
 *             \EndFor
 *             \State return $False$
 *         \EndFunction
 *     \end{algorithmic}
 * \end{algorithm}
 *
 * \begin{algorithm}
 * \vspace{10pt}
 *     \caption{Branch And Bound}
 *     \begin{algorithmic}[1]
 *         \Function{BranchBound}{$b, n$} \Comment{Where  $b = (b_{1},
 *          ..., b_{n})$ ordered basis of a Lattice}
 *             \State Compute $C=(c_{i,j})_{i,j \in [1..n]}$ Cholesky
 *          decomposition of Product Scalar Matrix.
 *         \State{ $v = b_{1}$}
 *         \State $Find = True$
 *         \While{Find} \Comment{While we find a shorter vector}
 *             \State $v \gets v'$
 *             \State $z = (z_{1}, ..., z_{n}) = (0 ... 0)$
 *             \State $Find \gets BBrec(v, b, n)$
 *         \EndWhile
 *         \EndFunction
 *     \end{algorithmic}
 * \end{algorithm}
 * \endlatexonly
 *
 *
 * The total time taken by this BB algorithm is roughly proportional to the number of
 * tree nodes that we visit.
 * One major drawback is that in the worst case, this number of nodes typically
 * grows exponentially with the dimension.
 * It is therefore important to reduce this number as much possible.
 * For this, it helps to start with a basis in which \f$\mathbf{v}_1\f$ is shorter,
 * because this shortens the search interval determined by the bounds {@link REF__eq_bounds (bounds)}
 * at each level \f$j\f$, and can therefore greatly reduce the number of nodes that must be examined.
 * Various heuristics discussed below help achieve this.
 * For the same reason, it also helps it we quickly find a tree leaf that corresponds to
 * an improved solution, because it can reduce (dynamically) the size of the tree.
 * We found experimentally that searching the BB tree depth-first from the center
 * is usually the most effective approach, because it permits one to find a shorter \f$\mathbf{v}_1\f$ faster.
 * That is, at each level \f$j\f$, instead of scanning the interval for \f$z_j\f$ from one size to the other,
 * we scan it by starting with the \f$z_j\f$ that is closest to 0, then we examine the second closest, etc.
 * **Pierre**: Correct?
 * With this procedure, the first visited branch corresponds
 * to the trivial ``solution'' in which \f$z_t = \cdots = z_1 = 0\f$,
 * and this solution is rejected.
 * The second visited branch corresponds to
 * \f$z_t = \cdots = z_2 = 0\f$ and \f$z_1=1\f$, i.e., \f$\mathbf{v} = \mathbf{v}_1\f$.
 *
 * Observe that if \f$\mathbf{v} = \mathbf{V}\mathbf{z}\f$ is a lattice vector, \f$-\mathbf{v} = \mathbf{V}(-\mathbf{z})\f$ is also a lattice
 * vector with exactly the same length.  We can exploit this symmetry to cut the BB tree in half,
 * simply by considering only non-negative values of \f$z_1\f$.
 * We can do that because any vector \f$\mathbf{z}\f$ with \f$z_1 < 0\f$ has an equivalent vector
 * \f$-\mathbf{z}\f$ having \f$z_1 > 0\f$.
 *
 * \subsection bb_prered Pre-reduction heuristics
 *
 * We now describe some heuristics that can be applied to pre-reduce (shorten)
 * the basis vectors before starting the BB algorithm.
 * The computing time invested with these heuristics is usually profitable
 * in small and moderate dimensions, and practically essential in large dimensions.
 *
 * \subsubsection prered_dieter Dieter pre-reduction
 * It is simple heuristic discussed in \cite rDIE75a \cite rKNU98a also known as
 * *pairwise reduction* method. It consists in trying to reduce the length of a
 * basis vector \f$\mathbf{v}_i\f$ by subtracting from it \f$q\f$ times another
 * basis vector \f$\mathbf{v}_j\f$, for some integer \f$q\f$ and given indices \f$i\not=j\f$.
 * One can easily verify that the Euclidean length of the new vector \f$\mathbf{v} = \mathbf{v}_i - q \mathbf{v}_j\f$
 * is minimized by taking \f$q = \lfloor \mathbf{v}_i^\mathbf{t}\mathbf{v}_j / \mathbf{v}_j^\mathbf{t} \mathbf{v}_j\rfloor\f$.
 * If this \f$q\f$ is nonzero, we can replace \f$\mathbf{v}_i\f$ by the strictly shorter vector
 * \f$\mathbf{v}_i - q \mathbf{v}_j\f$ in the basis.
 * If the dual basis is maintained, we must also replace \f$\mathbf{w}_j\f$ by \f$\mathbf{w}_j + q \mathbf{w}_i\f$
 * in the dual basis, so it remains consistent.
 * This can be tried with all pairs \f$i\not=j\f$, and repeated until running through all pairs
 * gives no further improvement.
 *
 * Pairwise reductions can also be applied to the dual basis.
 * The motivation is that reducing the vectors of the
 * dual basis often lead to a reduction of the vectors of the primal basis.
 * Here we try to reduce the length of a dual basis vector \f$\mathbf{w}_i\f$ by replacing this
 * vector by \f$\mathbf{w}_i - q \mathbf{w}_j\f$, where \f$q = \lfloor \mathbf{w}_i^\mathbf{t} \mathbf{w}_j / \mathbf{w}_j^\mathbf{t} \mathbf{w}_j\rfloor\f$.
 * If \f$q\not=0\f$ and if the corresponding primal basis vector \f$\mathbf{v}_j + q \mathbf{v}_i\f$
 * is not longer than \f$\mathbf{v}_j\f$, then we make the replacement.
 * This can also be tried for all pairs \f$i\not=j\f$, and repeated until it gives no improvement.
 * \remark Pierre: I do not fully understand why this is effective, because this is exactly
 *   equivalent to a pairwise reduction in the primal basis with \f$-q\f$ instead of \f$q\f$.
 *   To be verified.
 *   **Marc-Antoine**: This is true and should be noted. Dieter says that from his
 *   experiments this works well. I think the idea is that we reduce both the 
 *   primal and the dual basis this way, which is interesting in our use case.
 *   Maybe. Otherwise it might just be an empirical result that when we play 
 *   between both the reduction is better.
 * \remark **Pierre**: Note: In the LatMRG software, the pairwise reductions are not
 *  performed exactly in this order.
 *
 * \subsubsection prered_LLL LLL pre-reduction
 *
 * Lenstra, Lenstra, and Lovasz \cite mLEN82a have proposed a popular form of
 * lattice basis reduction known as *LLL reduction*. Our software implements/uses
 * (in most cases we use the NTL implementation) a slightly modified version of
 * this algorithm presented in \cite mSCH91a.
 *
 * Let us recall *Gram-Schmidt orthogonalization*. From the basis 
 * \f$\{\mathbf{v}_1, \ldots, \mathbf{v}_t\}\f$, we can get an orthogonal basis 
 * \f$\{\hat{\mathbf{v}}_1, \ldots, \hat{\mathbf{v}}_t\}\f$ by taking
 * \f[
 *   \hat{\mathbf{v}}_1 = \mathbf{v}_1, \ \hat{\mathbf{v}}_i = \mathbf{v}_i - 
 *   \sum_{j=1}^{i-1} \mu_{ij} \hat{\mathbf{v}}_j,\ \mu_{ij} = \frac{\mathbf{v}_i 
 *   \cdot \hat{\mathbf{v}}_j}{\hat{\mathbf{v}}_j \cdot \hat{\mathbf{v}}_j}
 * \f]
 * For a small \f$0 \leq \epsilon < 3/4\f$, we say that a basis is \f$\epsilon\f$-LLL 
 * reduced if
 *
 * 1.  \f$ |\mu_{ij}| \leq 1/2 \f$ for \f$1 \leq j < i \leq t\f$ ;
 * 2.  for \f$0 < i \leq t-1 \f$,
 *    \f$1-\epsilon \leq \frac{\Vert \hat{\mathbf{v}}_{i+1} + \mu_{i\,i+1} 
 *    \hat{\mathbf{v}}_i \Vert^2}{\Vert \hat{\mathbf{v}}_i\Vert^2}\f$;
 *
 * Here, the first condition means that for any \f$i \neq j\f$, it is not 
 * possible to reduce \f$\mathbf{v}_i\f$ by adding to it an integer multiple of 
 * \f$\mathbf{v}_j\f$. This is equivalent to one step of pairwise reduction in 
 * the primal. The second condition means that we want to 
 * sort the vectors so that \f$\mathbf{v}_i\f$ is the vector with the shortest 
 * projection on \f$\text{span}(\mathbf{v}_1, \ldots \mathbf{v}_{i-1})\f$ among
 * \f$\{\mathbf{v}_i, \ldots, \mathbf{v}_{t}\}\f$. Also note that in practice, we 
 * would like to take \f$0<\epsilon\f$ as small as possible.
 * 
 * This algorithm does a very simple `while` loop. From \f$k=2\f$ it performs 
 * pairwise reduction of \f$\mathbf{v}_k\f$ with \f$ \mathbf{v}_{k-1}, \ldots, 
 * \mathbf{v}_t\f$ and checks if the condition 2 is verified for \f$i = k-1\f$.
 * If it is, \f$k\f$ is incremented. If it's not, \f$\mathbf{v}_k\f$ and
 * \f$\mathbf{v}_{k-1}\f$ are swapped and \f$k\f$ is decremented if it is greater
 * than 2. Since the version we use has floating point arithmetic, it also has 
 * a few more steps to account for the possible error. Moreover, this algorithm
 * can be expanded to take a generating set of more than \f$t\f$ vectors of the 
 * lattice and still return a reduced basis (the last vectors in the reduced 
 * basis will be set to \f$\mathbf{0}\f$).
 *
 * This particular reduction does not necessarily returns the shortest vector as
 * \f$\mathbf{v}_1\f$. However, we have that \f$ 1 \leq \Vert \mathbf{v}_1 
 * \Vert^2 / \ell_t^2 \leq (3/4 - \epsilon)^{1-t}\f$ (\cite mSCH91a) and the 
 * lengths of the other basis vectors also not much larger than that of 
 * \f$\mathbf{v}_1\f$ after the reduction.
 *
 * For this reason, an LLL-reduced basis tends to yield a much thinner BB tree.
 * Moreover, an \f$\epsilon\f$-LLL reduction can be performed quickly (it is 
 * polynomial in the number of dimensions if the arithmetic is exact but could 
 * cycle indefinitely if \f$\epsilon\f$ is too close to 0 and the precision too
 * small). It is therefore very effective and useful. Some authors fix 
 * \f$\epsilon\f$ at 1/4 \cite mHEL85a \cite mLOV86a, but we prefer much smaller
 * values. In our implementations, we use \f$\epsilon = 10^{-6}\f$ as the 
 * default value.
 * 
 * \subsubsection prered_BKZ BKZ pre-reduction
 *
 * The block Korkin-Zolotarev algorithm that we use is the one presented in 
 * \cite mSCH91a (the one used in NTL). It is more costly than LLL, but it 
 * yields better results, leading to an accelerated *Branch and Bound* in some 
 * cases. This is basically a generalization of the LLL reduction using stronger
 * parameters. 
 *
 * \subsubsection prered_precision A note on precision
 * We should say a few words on precision. Also, we should advise the user that
 * if they only intend on using prereductions, they should only use NTL because
 * *LatticeTester* is just a wrapper most of the time.
 *
 */
